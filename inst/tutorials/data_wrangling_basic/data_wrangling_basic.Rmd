---
title: "Introduction to data wrangling"
author: "Michelle Kang"
date: "05/02/2020"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: this file contains the first of three data wrangling tutorials using the tidyverse package in R. Along with an introduction on downloading and loading packages, this tutorial introduces loading and visualising tabular data tables, and the filter, slice and select functions of tidyverse.  
---

```{r setup, include=FALSE}
# General learnr setup
library(learnr)
knitr::opts_chunk$set(echo = TRUE)
library(educer)
# Helper function to set path to images to "/images" etc.
setup_resources()

# Tutorial specific setup
library(tidyverse)

OTU_metadata_table <- combined
write.csv(combined, "Saanich_OTU_metadata.csv")
x = 10 #for boolean exercise
restricted_columns <- select(OTU_metadata_table, OTU0001,
                             OTU0002, OTU0004, Depth)
summary_solution_1 <-
  geochemicals %>%
  select(Cruise, Date, Depth, CTD_O2) %>%
  filter(Cruise == 72 & Depth >= 0.05)

summary_solution_2 <-
  geochemicals %>% 
  filter(CTD_O2 > 0 | NO3 > 0) %>% 
  select(Cruise, Depth)
```



## Objectives

### By the end of this tutorial you should be able to:

- Install and load R packages.
- Load tabular data using read_csv and save the data to your R environment.
- Use the filter, slice and select methods to conditionally subset your data.



## R packages

R packages are units of shareable code, containing functions that facilitate and enhance analyses. In simpler terms, think of R packages as iPhone Applications. Each App has specific functions and capabilities that can be accessed when we install then open the application. The same can be said about R packages. In order to use the functions for a specific R package, we first need to install the package, then each time we want to use the package we need to "open" the package. 

In this tutorial we will be using the "tidyverse" package. This package contains a versatile set of functions designed for easy manipulation of data.

### Installing Packages

The tidyverse package can be installed like this (to install a different package just replace "tidyverse" with the name of the desired package):

**For R v3.4 or newer**
```{R eval=FALSE}
install.packages("tidyverse")
```

**For R v3.3 or older**  
Unfortunately, tidyverse does not work on older versions of R. Instead, you will need to individually install each package within the tidyverse.
```{r eval=FALSE}
install.packages("tibble")
install.packages("readr")
install.packages("dplyr")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("stringr")
install.packages("purrr")
install.packages("forcats")
```



## Loading packages

After installing a package, and *everytime* you open a new RStudio session, the packages you want to use need to be loaded (opened) into the R work-space with the `library()` function. This tells R to access the package's functions and prevents RStudio from lags that would occur if it automatically loaded every downloaded package every time you opened it.

Packages can be loaded like this:

```{R tidyverse_load, exercise = TRUE, exercise.lines = 5}
library("tidyverse")
library("educer")
```

### Data description
The data used throughout this module were collected as part of an on-going oceanographic time series program in Saanich Inlet, a seasonally anoxic fjord on the East coast of Vancouver Island, British Columbia.

The data that you will use in R are 16S amplicon profiles of microbial communities at several depths in Saanich Inlet from one time point in this series (August 2012). These ~300 bp sequences were processed using [mothur](https://www.mothur.org/wiki/Main_Page) to yield 97% (approximately species-level) operational taxonomic units (OTUs). 

The OTU_metadata_table (`Saanich_OTU_metadata.csv`) is a comma-delimited table of counts of four OTUs in each sample, normalized to 100,000 sequences per sample and the corresponding conditions of each sample (Depth, NO2, NO3 etc). 

For a brief introduction to these data, see Hallam SJ et al. 2017. Monitoring microbial responses to ocean deoxygenation in a model oxygen minimum zone. Sci Data 4: 170158 [doi:10.1038/sdata.2017.158](https://www.nature.com/articles/sdata2017158).



## Loading tabular data

Every R function follows the following basic syntax, where `function()` is the name of the function and `arguments` are the different parameters you can specify.

`function(argument1=..., argument2=..., ...)`

Data tables can be loaded into R using the tidyverse `read_*()` function. 

The `read_table()` function allows us to open raw datafiles. Run the following code to see what `Saanich_OTU_metadata.csv` looks like. 

```{r message = FALSE}
read_table("Saanich_OTU_metadata.csv")
```

Notice how values in `Saanich_OTU_metadata.csv` are separated by commas. We can load our Saanich data into R with `read_csv()` for comma separated files and specify the arguments that describe our data as follows.

- `col_names`: tells R that the first row is column names, not data

```{r message = FALSE}
read_csv(file = "Saanich_OTU_metadata.csv", col_names = TRUE)
```

Now our data is formatted nicely into table form.

### Save data in the environment
Since we want to do more with our data after reading it in, we need to save it as a variable in R like we did previously with the `<-` operator. You can choose to name the object whatever you like, though this module assumes the names used below.
```{r message = FALSE}
OTU_metadata_table <- read_csv(file = "Saanich_OTU_metadata.csv", col_names = TRUE)
```


```{r saving-quiz, echo = FALSE}
quiz(
  question("How do we make sure the datatable is saved to 'OTU_metadata_table' in our environment?",
           answer("Entering `\"OTU_metadata_table\"` (with quotes) in the console displays the table."),
           answer("Entering `OTU_metadata_table` (no quotes) in the console displays the table.", correct = TRUE),
           answer("`OTU_metadata_table` shows up in the \"Global Environment\" box on the top right hand corner.", correct = TRUE)
           )
)
```



## Data exploration

Let's explore the data that we've imported into R. The simplest way to view your imported data is to view it as a "tibble" like this. This view displays a subset of large data tables (notice that the last column name gets cut off) in a table view

```{r tibble, exercise = TRUE, exercise.lines = 5}
OTU_metadata_table
```

`glimpse()` is a function that as its name suggests, allows us to get a "glimpse" of the contents of a data table. Running `glimpse()` on a data table outputs the number of rows (observations), columns (variables), and lists each column name along with its type and a portion of its contents. Let's run `glimpse()` with our OTU_metadata_table like this:

```{r glimpse, exercise = TRUE, exercise.lines = 5 }
glimpse(OTU_metadata_table)
```
from this we see that our table has 7 rows and 10 columns. Each $ is followed by a column name, with information on the contents following each column name. `glimpse()` lists all columns of a table

### Exercise

```{r glimpse-quiz, echo = FALSE}
quiz(
  question("Which columns are in the OTU_metadata_table?",
           answer("OTU001", correct = TRUE),
           answer("Otu002"),
           answer("72"),
           answer("NO3", correct = TRUE),
           answer("NO3_Mean"),
           answer("Mean_N2O", correct = TRUE),
           answer("Depth", correct = TRUE)
           )
)
```

If we only want the dimensions of a dataframe or table, we can use the `dim()` function which prints the number of rows followed by the number of columns. Simple functions to query just the number of rows or columns in a data table are `nrow()` and `ncol()`.

```{r dim, exercise = TRUE, exercise.lines = 5}
#number of rows followed by number of columns
dim(OTU_metadata_table)
#number of rows
nrow(OTU_metadata_table)
#number of columns
ncol(OTU_metadata_table)
```

We can list the column names using `colnames()`. 

```{R colnames,exercise = TRUE, exercise.lines = 5 }
colnames(OTU_metadata_table)
```



## Select

We can select to work with only specific columns from our table using the `select()` function. 

```{R select-1, exercise = TRUE, exercise.lines = 5}
restricted_columns <- select(OTU_metadata_table, OTU0001, OTU0002, OTU0004, Depth)
```

To view our new `restricted_columns` variable, just type in the variable name and run the code like this:

```{R  select-2, exercise = TRUE, exercise.lines = 5}
restricted_columns
```

### Exercise
As an exercise, select for only the depth and geochemical columns in `OTU_metadata_table` and name the new table `metadata`:

```{r select-exercise, exercise = TRUE, exercise.lines = 5}

```



## Booleans

Booleans are logical statements that are either `TRUE` or `FALSE` but can not be anything in between. As an example, run the code below:

```{r boolean-exercise, exercise = TRUE, exercise.lines = 5 }
x <- 6
y <- "cat"

x < 3
y == "dog"
```

The equation `x < 3` is `FALSE` because x is set to 6 in the line above. As a simple exercise, manipulate the above code to make both equations `TRUE`. 

note that in R, `==` is used in Boolean equations and using a single `=` will result in error. As you may have noticed above a single `=` is used to set a variable to a value. 

For quick reference, here are the most commonly used statements and operators.

R code     | meaning
---------- | ---------------
`==`       | equals
`< or >`   | less/greater than
`<= or >= `| less/greater than or equal to
`%in%`     | in
`is.na`    | is missing (`NA`)
`!`        | not (as in not equal to `!=`)
`&`        | and
`|`        | or


### Exercise

Write a boolean equation for "x is greater than 6 or less than 12", it should return `TRUE` after running.

```{r boolean-exercise-2, exercise = TRUE, exercise.lines = 5 }

```

You can use `filter()` to select specific rows based on a logical condition of a variable.
Some examples working with our `OTU_metadata_table` data.

`variable == value` returns rows where the variable matches the value:

```{r equal-to, exercise = TRUE, exercise.lines = 5  }
filter(OTU_metadata_table, Depth == 100)
```

`variable != value` returns rows where the variable does not match the value:

```{r not-equal-to, exercise = TRUE, exercise.lines = 5 }
filter(OTU_metadata_table, Depth != 100)
```

`variable > value` returns rows where the variable is greater than the value:

```{r greater-than, exercise = TRUE, exercise.lines = 5 }
filter(OTU_metadata_table, Depth > 100)
```

`variable %in% values` returns rows where the variable matches one of the given values.
Values are provided as a vector `c(value1, value2, ...)`:

```{r match-in, exercise = TRUE, exercise.lines = 5 }
filter(OTU_metadata_table, Depth %in% c(100, 200))
```

### Exercise

As an exercise, restrict for rows where the value for "depth" is less than or equal to 135m. 
```{r filter-exercise, exercise = TRUE, exercise.lines = 5}

```



## Slice

We can also only choose to work with specific rows in our data table using the `slice()` function. 

To select a subset of observations (rows) by their ordinal position, we use the `slice()` function.

```{r slice-1, exercise = TRUE, exercise.lines = 5 }
slice(OTU_metadata_table, 1)
```

You can list multiple ordinal postions to select multiple observations at once.

```{r slice-2, exercise = TRUE, exercise.lines = 5 }
slice(OTU_metadata_table, 1, 2, 3, 4, 5)
```

If you would like to to select a range of observations, give the starting and end position separated by a colon like so: `Start:End`.

```{r slice-3, exercise = TRUE, exercise.lines = 5}
slice(OTU_metadata_table, 1:5)
```

```{r slice-quiz, echo = FALSE}
quiz(
  question("What is the value of OTU0003 in the 6th row of OTU_metadata_table?",
           answer("0"),
           answer("156"),
           answer("178", correct=TRUE),
           answer("72")
           )
)
```



## Summary Exercise

The `geochemicals` dataset is included in the "educer" package. This dataframe contains time series observations on the water column chemistry. Learn more about the `geochemicals` dataset by running the following line in your R console. 

```{r dataset_exercise, exercise = TRUE, exercise.lines = 5}
?geochemicals
```

Using the geochemical data:

1. Select the Cruise, Date, Depth, and oxygen variables.
2. Filter the data to retain data on Cruise 72 where Depth is greater than or equal to 0.05 km.

Your resulting pdat object should be a [`r dim(summary_solution_1)`] data frame. The data has been loaded for you into the `dat` variable.

```{r summary-exercise, exercise = TRUE, exercise.lines = 5}
dat <- geochemicals
```

### Challenge exercise: `select()` and `filter()`

If you want more practice or have previous experience in R, try this more challenging exercise! Be sure to create a fresh `dat`.

3. Keep only the Cruise and Depth variables and the rows where oxygen OR nitrate is greater than zero.

Your resulting pdat object should be a [`r dim(summary_solution_2)`] data frame. *Hint:* Can you filter based on a variable that you previously removed by not selecting it?

```{r summary-exercise-2, exercise = TRUE, exercise.lines = 5}
dat <- geochemicals
```
