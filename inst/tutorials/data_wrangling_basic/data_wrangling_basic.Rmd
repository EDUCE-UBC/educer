---
title: "Tidyverse Intro"
author: "michelle kang"
date: "05/02/2020"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(learnr)
library(tidyverse)
```

## Objectives:

### By the end of this tutorial you should be able to

- load and subset tabular data using tidyverse

## R packages

R packages are units of shareable code, containing functions that facilitate and enhance analyses. In simpler terms, think of R packages as iPhone Applications. Each App has specific functions and capabilities that can be accessed when we install then open the application. The same can be said about R packages. In order to use the functions for a specific R package, we first need to install the package, then each time we want to use the package we need to "open" the package. 

In this tutorial we will be using the "tidyverse" package. This package contains a versatile set of functions designed for easy manipulation of data.

### Installing Packages

The tidyverse package can be installed like this (to install a different package just replace "tidyverse" with the name of the desired package):

**For R v3.4 or newer**
```{r eval=FALSE}
install.packages("tidyverse")
```

**For R v3.3 or older**  
Unfortunately, tidyverse does not work on older versions of R. Instead, you will need to individually install each package within the tidyverse.
```{r eval=FALSE}
install.packages("tibble")
install.packages("readr")
install.packages("dplyr")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("stringr")
install.packages("purrr")
install.packages("forcats")
```

## Loading packages:

After installing a package, and *everytime* you open a new RStudio session, the packages you want to use need to be loaded (opened) into the R work-space with the `library` function. This tells R to access the package's functions and prevents RStudio from lags that would occur if it automatically loaded every downloaded package every time you opened it.

Packages can be loaded like this:

```{r eval=TRUE}
library("tidyverse")
```

### Data description
The data used throughout this module were collected as part of an on-going oceanographic time series program in Saanich Inlet, a seasonally anoxic fjord on the East coast of Vancouver Island, British Columbia.

The data that you will use in R are 16S amplicon profiles of microbial communities at several depths in Saanich Inlet from one time point in this series (August 2012). These ~300 bp sequences were processed using [mothur](https://www.mothur.org/wiki/Main_Page) to yield 97% (approximately species-level) operational taxonomic units (OTUs). 

The OTU_metadata_table (`Saanich_OTU_metadata.csv`) is a comma-delimited table of counts of four OTUs in each sample, normalized to 100,000 sequences per sample and the corresponding conditions of each sample (Depth, NO2, NO3 etc). 

For a brief introduction to these data, see Hallam SJ et al. 2017. Monitoring microbial responses to ocean deoxygenation in a model oxygen minimum zone. Sci Data 4: 170158 [doi:10.1038/sdata.2017.158](https://www.nature.com/articles/sdata2017158).

## Loading tabular data

Every R function follows the following basic syntax, where `Function` is the name of the function and `arguments` are the different parameters you can specify.

Function(argument1=..., argument2=..., ...)

Data tables can be loaded into R using the tidyverse `read_*` function. 

For example, we can load our Saanich data into R with `read_csv` for a comma separated file and specify the arguments that describe our data as follows.

* col_names: tells R that the first row is column names, not data

```{r}
read_csv(file="Saanich_OTU_metadata.csv", col_names = TRUE)
```

### Save data in the environment
Since we want to do more with our data after reading it in, we need to save it as a variable in R like we did previously with the `<-` operator. You can choose to name the object whatever you like, though this module assumes the names used below.
```{r}
OTU_metadata_table <- read_csv(file="Saanich_OTU_metadata.csv", col_names = TRUE)
```

## Data exploration

Let's explore the data that we've imported into R. `glimpse` is a function that as its name suggests, allows us to get a "glimpse" of the contents of a data table. Running `glimpse` on a data table outputs the number of rows (observations), columns (variables), and lists each column name along with its type and a portion of its contents. Let's run `glimpse` with our OTU_metadata_table like this:

```{r}
glimpse(OTU_metadata_table)
```
from this we see that our table has 7 rows and 10 columns. Each $ is followed by a column name, with information on the contents following each column name.

If we only want the dimensions of a dataframe or table, we can use the dim function which prints the number of rows followed by the number of columns. Simple functions to query just the number of rows or columns in a data table are `nrow` and `ncol`.

```{r}
#number of rows followed by number of columns
dim(OTU_metadata_table)
#number of rows
nrow(OTU_metadata_table)
#number of columns
ncol(OTU_metadata_table)
```

We can list the column names using `colnames()`. 

```{R}
colnames(OTU_metadata_table)
```

We can select to work with only specific columns from our table using the `select()` function. 

```{R}
restricted_columns <- select(OTU_metadata_table, sample, Otu0001, Otu0002, Otu0004, Depth_m)
```

As an exercise, select for only the depth and geochemical columns in OTU_metadata_table and name the new table "metadata" 
```{r select_exercise, exercise = TRUE, exercise.lines = 5}

```

## Booleans

Booleans are logical statements that are either TRUE or FALSE but can not be anything in between. For example:

the equation x < 3 is TRUE when x is less than 3 and FALSE when x is greater than 3.

the equation x == "DOG" is TRUE when x is "DOG" and FALSE when x is not "DOG"

note that in R, "==" is used in Boolean equations and using a single "=" will result in error. 

For quick reference, here are the most commonly used statements and operators.

R code     | meaning
---------- | ---------------
`==`       | equals
`< or >`   | less/greater than
`<= or >= `| less/greater than or equal to
`%in%`     | in
`is.na`    | is missing (NA)
`!`        | not (as in not equal to `!=`)
`&`        | and
`|`        | or

You can use `filter` to select specific rows based on a logical condition of a variable.
Some examples working with our `OTU_metadata_table` data.

`variable == value` returns rows where the variable matches the value
```{r}
filter(OTU_metadata_table, Depth_m == 100)
```

`variable != value` returns rows where the variable does not match the value
```{r}
filter(OTU_metadata_table, Depth_m != 100)
```

`variable > value` returns rows where the variable is greater than the value
```{r}
filter(OTU_metadata_table, Depth_m > 100)
```

`variable %in% values` returns rows where the variable matches one of the given values.
Values are provided as a vector `c(value1, value2, ...)`
```{r}
filter(OTU_metadata_table, Depth_m %in% c(100, 200))
```

As an exercise, restrict for rows where the value for "depth" is less than or equal to 135m. 
```{r filter_exercise, exercise = TRUE, exercise.lines = 5}

```


## Slice
We can also only choose to work with specific rows in our data table using the `slice()` function. 

To select a subset of observations (rows) by their ordinal position, we use the `slice` function.
```{r}
slice(OTU_metadata_table, 1)
```

You can list multiple ordinal postions to select multiple observations at once.
```{r}
slice(OTU_metadata_table, 1, 2, 3, 4, 5)
```

If you would like to to select a range of observations, give the starting and end position separated by a colon like so: `Start:End`.

```{r}
slice(OTU_metadata_table, 1:5)
```

