---
title: "Introduction to data wrangling"
author: "Michelle Kang"
date: "05/02/2020"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: This file contains the first of three data wrangling tutorials using the tidyverse package in R. Along with an introduction on downloading and loading packages, this tutorial introduces loading and visualising tabular data tables, and the filter, slice and select functions of tidyverse.  
---

```{r setup, include = FALSE}
# General learnr setup
library(learnr)
knitr::opts_chunk$set(echo = TRUE)
library(educer)
# Helper function to set path to images to "/images" etc.
setup_resources()

# Tutorial specific setup
library(readr)
library(tidyverse)

OTU_metadata_table <- combined

subset_dat <- slice(geochemicals, 710, 713, 715, 716, 709, 717, 718, 719)

x = 10 #for boolean exercise
restricted_columns <- select(OTU_metadata_table, OTU0001,
                             OTU0002, OTU0004, Depth)
summary_solution_1 <-
  geochemicals %>%
  select(Cruise, Date, Depth, CTD_O2) %>%
  filter(Cruise == 72 & Depth >= 0.05)

summary_solution_2 <-
  geochemicals %>% 
  filter(CTD_O2 > 0 | NO3 > 0) %>% 
  select(Cruise, Depth)
```



## Objectives

### By the end of this tutorial you should be able to:

- Install and load R packages.
- Load tabular data using `read_csv()` and save the data to your R environment.
- Use the `filter()`, `slice()` and `select()` methods to conditionally subset your data.





## Loading packages

After installing a package, and *everytime* you open a new RStudio session, the packages you want to use need to be loaded (opened) into the R work-space with the `library()` function. This tells R to access the package's functions and prevents RStudio from lags that would occur if it automatically loaded every downloaded package every time you opened it.

Packages can be loaded like this:

```{r tidyverse_load, exercise = TRUE, exercise.lines = 5}
library(tidyverse)
library(educer)
```


## Tidyverse vs. base R

The [tidyverse](https://www.tidyverse.org/) is a collection of R packages for data wrangling, analysis, and visualization.

The main advantages of using the tidyverse to read in data over base R are:

- Faster data processing
- Seamless integration with other tidyverse functions
- Automatic designation of data types
- Data storage in tibble as opposed to data frames
    - Tibbles are data frames with an additional layer of formatting that causes them to print nicely in the console and always return a tibble in functions
    
    
A popular package for data wrangling is *dplyr* in the tidyverse. This package is so good at what it does, and integrates so well with other popular tools like *ggplot2*, that it has rapidly become the de-facto standard.

dplyr code is very readable because all operations are based on using dplyr functions or *verbs* (select, filter, mutate...). 

Typical data wrangling tasks in dplyr:

- `select()` a subset of variables (columns)
- `slice()` out rows by their ordinal position in the tbl
- `filter()` out a subset of observations (rows)
- `rename()` variables
- `arrange()` the observations by sorting a variable in ascending or descending order
- `mutate()` all values of a variable (apply a transformation)
- `group_by()` a variable and `summarise` data by the grouped variable
- `*_join()` two data frames into a single data frame

Each verb works similarly:

- Input data frame in the first argument.
- Other arguments can refer to variables as if they were local objects
- Output is another data frame

Before working with our data, we first want to make a copy of the raw data so that we may revert to it quickly if we make any mistakes. This is best practices for data science in general.

```{r}
# dat <- raw_dat
```

We will then continually overwrite this object with `<-` as we clean it in R.

<!-- ### Data description test -->

<!-- ``` {r child = system.file("resources/markdown", "data_description.Rmd", package = "educer")} -->
<!-- ``` -->

### Data description
The data used throughout this module were collected as part of an on-going oceanographic time series program in Saanich Inlet, a seasonally anoxic fjord on the East coast of Vancouver Island, British Columbia.

The data that you will use in R are 16S amplicon profiles of microbial communities at several depths in Saanich Inlet from one time point in this series (August 2012). These ~300 bp sequences were processed using [mothur](https://www.mothur.org/wiki/Main_Page) to yield 97% (approximately species-level) operational taxonomic units (OTUs). 

`combined` is a comma-delimited table of counts of four OTUs in each sample, normalized to 100,000 sequences per sample and the corresponding conditions of each sample (Depth, NO2, NO3 etc). 

For a brief introduction to these data, see Hallam SJ et al. 2017. Monitoring microbial responses to ocean deoxygenation in a model oxygen minimum zone. Sci Data 4: 170158 [doi:10.1038/sdata.2017.158](https://www.nature.com/articles/sdata2017158).

Click the button below to save a copy of this data set to your computer:

```{r echo = FALSE}
# Download button shiny app UI
fluidRow(
  column(12, align = "center", downloadButton("downloadData", "Download"))
)

```

```{r context = "server"}
# Download button shiny app server
output$downloadData <- downloadHandler(
  filename = "combined.csv",
  content = function(file) {
    write_csv(combined, file)
  }
)
```

## Loading tabular data

Every R function follows the following basic syntax, where `function()` is the name of the function and `arguments` are the different parameters you can specify.

`function(argument1=..., argument2=..., ...)`

Data tables can be loaded into R using the tidyverse `read_*()` function. 

The `read_table()` function allows us to open raw datafiles. Run the following code to see what `combined.csv` looks like. 

```{r eval = FALSE}
read_table("combined.csv")
```

Notice how values in `combined.csv` are separated by commas. We can load our Saanich data into R with `read_csv()` for comma separated files and specify the arguments that describe our data as follows.

- `col_names`: tells R that the first row is column names, not data

```{r eval = FALSE}
read_csv(file = "combined.csv", col_names = TRUE)
```

Now our data is formatted nicely into table form.

### Save data in the environment

Since we want to further manipulate our dataset after reading it in, we need to save it as a variable in R like we did previously with the `<-` operator. You can name the object whatever you like, though this module will assume the names used below.

```{r eval = FALSE}
OTU_metadata_table <- read_csv(file = "combined.csv", col_names = TRUE)
```

```{r saving-quiz, echo = FALSE}
quiz(
  question("How do we make sure the datatable is saved to 'OTU_metadata_table' in our environment?",
           answer("Entering `\"OTU_metadata_table\"` (with quotes) in the console displays the table."),
           answer("Entering `OTU_metadata_table` (no quotes) in the console displays the table.", correct = TRUE),
           answer("`OTU_metadata_table` shows up in the \"Global Environment\" box on the top right hand corner.", correct = TRUE)
           )
)
```

## Data exploration

Let's explore the data that we've imported into R. The simplest way to view your imported data is to view it as a "tibble" like this. This view displays a subset of large data table.

```{r tibble, exercise = TRUE, exercise.lines = 5}
OTU_metadata_table
```

`glimpse()` is a function that, as its name suggests, allows us to get a "glimpse" of the contents of a data table. Running `glimpse()` on a data table outputs the number of rows (observations), columns (variables), and lists each column name along with its type and a portion of its contents. Let's run `glimpse()` with our OTU_metadata_table like this:

```{r glimpse, exercise = TRUE, exercise.lines = 5}
glimpse(OTU_metadata_table)
```
from this we see that our table has 7 rows and 10 columns. Each $ is followed by a column name, with information on the contents following each column name. `glimpse()` lists all columns of a table

### Exercise

```{r glimpse-quiz, echo = FALSE}
quiz(
  question("Which columns are in the OTU_metadata_table?",
           answer("OTU001", correct = TRUE),
           answer("Otu002"),
           answer("72"),
           answer("NO3", correct = TRUE),
           answer("NO3_Mean"),
           answer("Mean_N2O", correct = TRUE),
           answer("Depth", correct = TRUE)
           )
)
```

If we only want the dimensions of a dataframe or table, we can use the `dim()` function which prints the number of rows followed by the number of columns. Simple functions to query just the number of rows or columns in a data table are `nrow()` and `ncol()`.

```{r dim, exercise = TRUE, exercise.lines = 5}
#number of rows followed by number of columns
dim(OTU_metadata_table)
#number of rows
nrow(OTU_metadata_table)
#number of columns
ncol(OTU_metadata_table)
```

We can list the column names using `colnames()`. 

```{R colnames,exercise = TRUE, exercise.lines = 5}
colnames(OTU_metadata_table)
```


## `select()`

You can use the `select()` function to keep only a subset of variables (columns). Let's select the variables `OTU0001`, `OTU0002`, `OTU0004`, `Depth`.

```{R select-1, exercise = TRUE, exercise.lines = 5}
restricted_columns <- select(OTU_metadata_table, OTU0001, OTU0002, OTU0004, Depth)
```

To view our new `restricted_columns` variable, just type in the variable name and run the code like this:

```{R  select-2, exercise = TRUE, exercise.lines = 5}
restricted_columns
```

### Exercise
As an exercise, select for only the depth and geochemical columns (Depth, NO3, Mean_NO2, Mean_N2O, and Mean_NH4) in `OTU_metadata_table` and name the new table `metadata`:

```{r select-exercise, exercise = TRUE, exercise.lines = 5}

```

```{r select-exercise-hint-1}
select(OTU_metadata_table, <variable1>, <variable2>, <...>)
```

```{r select-exercise-hint-2}
select(OTU_metadata_table, Depth, NO3, Mean_NO2, Mean_N2O, Mean_NH4)
```
<!-- ### Exercise: `select()` -->

<!-- Select the Cruise, Date, Depth, PO4, and WS_NO3 variables of the `geochemicals` data set -->

<!-- ```{r select-exercise-1, exercise=TRUE, exercise.lines = 3} -->

<!-- dat <- select() -->

<!-- dat -->
<!-- ``` -->




## Booleans

Booleans are logical statements that are either `TRUE` or `FALSE` but can not be anything in between. As an example, run the code below:

```{r boolean-exercise, exercise = TRUE, exercise.lines = 5}
x <- 6
y <- "cat"

x < 3
y == "dog"
```

The equation `x < 3` is `FALSE` because x is set to 6 in the line above. As a simple exercise, manipulate the above code to make both equations `TRUE`. 

```{r boolean-exercise-hint-1}
#x <- A number less than 3
#y <- A string

x < 3
y == "dog"
```

```{r boolean-exercise-hint-2}
x <- 1
y <- "dog"

x < 3
y == "dog"
```

Note that in R, `==` is used in Boolean equations and using a single `=` will result in error. As you may have noticed above a single `=` is used to set a variable to a value. 

For quick reference, here are the most commonly used statements and operators.

R Operator | Meaning
---------- | ---------------
`==`       | equals
`< or >`   | less/greater than
`<= or >= `| less/greater than or equal to
`%in%`     | in
`is.na`    | is missing (`NA`)
`!`        | not (as in not equal to `!=`)
`&`        | and
`|`        | or


### Exercise

Write a boolean equation for "x is greater than 6 or less than 12", it should return `TRUE` after running.

```{r boolean-exercise-2, exercise = TRUE, exercise.lines = 5}

```

```{r boolean-exercise-2-hint-1}
# Consider how we represent the "greater/less than" 
# operator and the "OR" operator in R.

# "x is greater than n" can be represented in the following way.
x > n
```

```{r boolean-exercise-2-hint-2}
# "x is greater than n or less than m" can be represented in the following way.
x > n | x < m
```


### `filter()`

Conditional statements and logical operators are important when working with data in R. We will practice using different conditional statements and logical operators on the oxygen data in a subset of the `geochemicals` data set. You can use `filter()` to select specific rows based on a logical condition of a variable.


```{r}
subset_dat <- slice(geochemicals, 710, 713, 715, 716, 709, 717, 718, 719)
```

`variable == value` returns rows where the variable matches the value:

```{r equal-to, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 == 204.259)
```

`variable != value` returns rows where the variable does not match the value:

```{r not-equal-to, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 != 204.259)
```

`variable > value` returns rows where the variable is greater than the value:

```{r greater-than, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 > 204.259)
```

`variable %in% values` returns rows where the variable matches one of the given values.
Values are provided as a vector `c(value1, value2, ...)`:

```{r match-in, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 %in% c(40.745, 204.259))
```

`is.na(variable)` returns rows where the variable is `NA` (Not Available).

```{r is-na, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, is.na(CTD_O2))
```

`!condition` returns rows where the condition is not fulfilled.

```{r opposite, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, !is.na(CTD_O2))
```

We can look for a range of values by finding the rows where the value of the variable is <= 120 **AND** >= 20 bu using the logical operator `&`.

```{r and, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 <= 120 & CTD_O2 >= 20)
```

Lastly, we can use the logical OR (`|`) to find the rows where the value is <= 50 **OR** >= 150.

```{r or, exercise = TRUE, exercise.lines = 5}
filter(subset_dat, CTD_O2 <= 50 | CTD_O2 >= 150)
```

### Exercise

As an exercise, restrict for rows where the value for "depth" is less than or equal to 135m. 
```{r filter-exercise, exercise = TRUE, exercise.lines = 5}

```

```{r filter-exercise-hint-1}
# Recall the general syntax for filtering.
filter(dataset, (column, operator, quantity))
```

```{r filter-exercise-hint-2}
filter(subset_dat, depth <= 135)
```

## `slice()`

We can also only choose to work with specific rows in our data table using the `slice()` function. 

To select a subset of observations (rows) by their ordinal position, we use the `slice()` function.

```{r slice-1, exercise = TRUE, exercise.lines = 5}
slice(OTU_metadata_table, 1)
```

You can list multiple ordinal postions to select multiple observations at once.

```{r slice-2, exercise = TRUE, exercise.lines = 5}
slice(OTU_metadata_table, 1, 2, 3, 4, 5)
```

If you would like to to select a range of observations, give the starting and end position separated by a colon like so: `<start>:<end>`.

```{r slice-3, exercise = TRUE, exercise.lines = 5}
slice(OTU_metadata_table, 1:5)
```

```{r slice-quiz, echo = FALSE}
quiz(
  question("What is the value of OTU0003 in the 6th row of OTU_metadata_table?",
           answer("0"),
           answer("156"),
           answer("178", correct=TRUE),
           answer("72")
           )
)
```

### Exercise: `slice()` and `select()`
Using `slice()` and `select()`, determine:

A) what depth value occurs in the 20th row?
B) what methane value occurs in the 170th row?
    
```{r slice_exercise, exercise=TRUE, exercise.lines=5}
dat <- geochemicals
```

```{r slice_exercise-hint-1}
# Recall that slice() allows you to find a row
# and select() allows you to find a column
```

```{r slice_exercise-hint-2}
slice(dat, 20)
select(dat, depth)
```

```{r slice_exercise-hint-2}
slice(select(dat, Depth), 20)
select(slice(dat, 170), methane)
```
## Summary Exercise

The `geochemicals` dataset is included in the "educer" package. This dataframe contains time series observations on the water column chemistry. Learn more about the `geochemicals` dataset by running the following line in your R console. 

```{r dataset_exercise, exercise = TRUE, exercise.lines = 5}
?geochemicals
```

Using the geochemical data:

1. Select the Cruise, Date, Depth, and oxygen variables.
2. Filter the data to retain data on Cruise 72 where Depth is greater than or equal to 0.05 km.

Your resulting pdat object should be a [`r dim(summary_solution_1)`] data frame. The data has been loaded for you into the `dat` variable.

```{r summary-exercise, exercise = TRUE, exercise.lines = 5}
dat <- geochemicals
```

### Challenge exercise: `select()` and `filter()`

If you want more practice or have previous experience in R, try this more challenging exercise! Be sure to create a fresh `dat`.

3. Keep only the Cruise and Depth variables and the rows where oxygen OR nitrate is greater than zero.

Your resulting pdat object should be a [`r dim(summary_solution_2)`] data frame. *Hint:* Can you filter based on a variable that you previously removed by not selecting it?

```{r summary-exercise-2, exercise = TRUE, exercise.lines = 5}
dat <- geochemicals
```

## Additional resources

* [R cheatsheets](https://www.rstudio.com/resources/cheatsheets/) also available in RStudio under Help > Cheatsheets
* [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)
* [dplyr tutorial](https://rpubs.com/justmarkham/dplyr-tutorial)
* [dplyr video tutorial](https://www.r-bloggers.com/hands-on-dplyr-tutorial-for-faster-data-manipulation-in-r/)
